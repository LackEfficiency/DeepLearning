{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10QkMZR-6TuoO6aenT9HXreXJ5nUy814_","authorship_tag":"ABX9TyPyGQQ+n1lXoSgEKHGnxf98"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"24J4veaHy4m_","executionInfo":{"status":"ok","timestamp":1711843573741,"user_tz":-660,"elapsed":353,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"outputs":[],"source":["%matplotlib inline\n","from __future__ import print_function\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgHq5_IA-X1s","executionInfo":{"status":"ok","timestamp":1711843586954,"user_tz":-660,"elapsed":12870,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"4ff4a63f-46b4-4b9b-9e17-2da463ccbee6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["train = np.load(\"drive/MyDrive/train_data.npy\")\n","train_label = np.load(\"drive/MyDrive/train_label.npy\")\n","test = np.load(\"drive/MyDrive/test_data.npy\")\n","test_label = np.load(\"drive/MyDrive/test_label.npy\")"],"metadata":{"id":"xtZ0LLli9atq","executionInfo":{"status":"ok","timestamp":1711843592950,"user_tz":-660,"elapsed":5997,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train[:10, :]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dm1afgaMAESg","executionInfo":{"status":"ok","timestamp":1711843592950,"user_tz":-660,"elapsed":2,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"bc1924a5-084a-4e97-aca4-07b6190f7af2"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ -6.40101763,   2.72903876,   1.50171052, ...,   0.22933369,\n","         -0.1535829 ,   0.54404128],\n","       [  0.82978338,  -0.94994322,   6.0037526 , ...,   0.04319449,\n","         -0.0157158 ,  -0.28907615],\n","       [  7.73019978, -11.52210233,  -2.75362051, ...,   0.01458726,\n","         -0.35582987,   0.18428758],\n","       ...,\n","       [ -0.95665174,   4.98697009,  -1.85796096, ...,  -0.38416269,\n","         -0.26883811,   0.06904308],\n","       [  6.53338386,   2.32932422,   2.11608296, ...,   0.24489259,\n","          0.29264692,   0.09669723],\n","       [ -7.24712665,  -8.00795779,  -6.74123202, ...,   0.3548907 ,\n","         -0.38102421,   0.67609394]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUY3Rsz9AQDG","executionInfo":{"status":"ok","timestamp":1711843594855,"user_tz":-660,"elapsed":344,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"92bdfcb2-5ff2-4889-d098-ab41391720d5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 128)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train_label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csC-CTTwaw2N","executionInfo":{"status":"ok","timestamp":1711843595746,"user_tz":-660,"elapsed":394,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"aea59589-dd52-4102-8659-5271e21598ab"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6],\n","       [9],\n","       [9],\n","       ...,\n","       [9],\n","       [1],\n","       [1]], dtype=uint8)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#Define activation class\n","class Activation(object):\n","  def __relu(self, x):\n","    return np.maximum(x, 0)\n","\n","  def __relu_deriv(self, a):\n","    # a = relu(x)\n","    a[a <= 0] = 0\n","    a[a > 0] = 1\n","    return a\n","\n","  def __init__(self, activation = 'relu'):\n","    self.f = self.__relu\n","    self.f_deriv = self.__relu_deriv"],"metadata":{"id":"7p9jtIANCjFJ","executionInfo":{"status":"ok","timestamp":1711843596884,"user_tz":-660,"elapsed":2,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Define HiddenLayer\n","class HiddenLayers(object):\n","  def __init__(self, n_in, n_out, activation_last_layer = 'relu', activation = 'relu', W = None, b = None, miniBatch = None):\n","    self.input = None\n","    self.activation = Activation(activation).f\n","\n","    #store momentum\n","    self.V_w = np.zeros_like(n_in)\n","    self.V_b = 0\n","\n","    #miniBatSize\n","    self.miniBatch = 1 if not miniBatch else miniBatch\n","\n","    #activation deriv of last layer\n","    self.activation_deriv = None\n","    if activation_last_layer:\n","      self.activation_deriv = Activation(activation_last_layer).f_deriv\n","\n","    #Assign init values for weights\n","    self.W = np.random.uniform(\n","        low = -np.sqrt(6. / (n_in + n_out)),\n","        high = np.sqrt(6. / (n_in + n_out)),\n","        size = (n_in, n_out)\n","    )\n","\n","    #Assign init values for bias\n","    self.b = np.zeros(n_out, )\n","\n","    #Assign init values for gradations\n","    self.grad_W = np.zeros(self.W.shape)\n","    self.grad_b = np.zeros(self.b.shape)\n","\n","  #the forward and backward progress for each training epoch\n","  def forward(self, input):\n","    '''\n","    input: np.array\n","    '''\n","    lin_output = np.dot(input, self.W) + self.b\n","    self.output = (\n","        lin_output if self.activation is None\n","        else self.activation(lin_output)\n","    )\n","    self.input = input\n","    return self.output\n","\n","  def backward(self, delta, output_layer = False):\n","    self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta)) / self.miniBatch\n","    if self.miniBatch != 1:\n","      self.grad_b = np.mean(delta.T, axis = 1)\n","    else:\n","      self.grad_b = delta\n","    if self.activation_deriv:\n","      delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n","    return delta"],"metadata":{"id":"psBLtm0GEaUn","executionInfo":{"status":"ok","timestamp":1711868812814,"user_tz":-660,"elapsed":1,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":263,"outputs":[]},{"cell_type":"code","source":["#MLP\n","class MLP:\n","  #last layer is softmax\n","  def __init__(self, layers, activation = [None, 'relu', None], momentum = None, miniBatch = None):\n","    '''\n","    layers: A list containing the number of units in each layer\n","    activatoin: the activation function to be used.\n","    momentum: A float number to determine if use momentum, what's the value of gamma\n","    MiniBatch: An int number to determine if use miniBatch, what's the size of batch\n","    '''\n","    #momentum param\n","    self.momentum = momentum\n","\n","    #MiniBatch param\n","    self.miniBatch = miniBatch\n","\n","    #initialize layers\n","    self.layers = []\n","    self.params = []\n","    self.activation = activation\n","    for i in range(len(layers)-1):\n","      self.layers.append(HiddenLayers(layers[i], layers[i+1], activation[i], activation[i+1], miniBatch = self.miniBatch))\n","\n","  #forward progress\n","  def forward(self, input):\n","    for layer in self.layers:\n","      output = layer.forward(input)\n","      input = output\n","    return self.softmax(output)\n","\n","  #define the softmax and loss function\n","  def softmax(self, z):\n","    exp_z = np.exp(z - np.max(z))\n","    if len(exp_z.shape) == 1:\n","      #SGD\n","      return exp_z / np.sum(exp_z)\n","    else:\n","      #Batch\n","      return exp_z / np.sum(exp_z, axis = 1, keepdims = True)\n","\n","  def cross_entropy_loss(self, y_hat, y):\n","    epsilon = 1e-15 #prevent log(0)\n","    #SGD\n","    if len(y.shape) == 1:\n","      loss = -np.sum(y * np.log(y_hat + epsilon))\n","    #MiniBatch\n","    else:\n","      loss = -np.mean(np.sum(y * np.log(y_hat + epsilon), axis = 1, keepdims = True))\n","    delta = y_hat - y\n","    return loss, delta\n","\n","  #backward progress\n","  def backward(self, delta):\n","    #output layer using softmax and cross-entropy\n","    #delta = self.layers[-1].backward(delta, output_layer = True)\n","    for layer in reversed(self.layers):\n","      delta = layer.backward(delta)\n","\n","  #update the weights\n","  #Using momentum\n","  def update(self, lr):\n","    if self.momentum:\n","      for layer in self.layers:\n","        V_w = self.momentum * layer.V_w + lr * layer.grad_W\n","        layer.V_w = V_w\n","        V_b = self.momentum * layer.V_b + lr * layer.grad_b\n","        layer.V_b = V_b\n","        layer.W -= V_w\n","        layer.b -= V_b\n","        #print(np.sum(layer.W))\n","    else:\n","      for layer in self.layers:\n","        layer.W -= lr * layer.grad_W\n","        layer.b -= lr * layer.grad_b\n","        #print(np.sum(layer.W))\n","\n","  #define the training function\n","  def fit(self, X, y, learning_rate = 0.1, epochs = 100):\n","    \"\"\"\n","    X: Input data\n","    y: Input targets\n","    learning_rate: the speed of learning\n","    epochs: number of times the dataset is presented to the network for learning\n","    \"\"\"\n","    X = np.array(X)\n","    y = np.array(y)\n","    to_return = np.zeros(epochs)\n","\n","    #SGD\n","    if not self.miniBatch:\n","      print(\"SGD\")\n","      for k in range(epochs):\n","        loss = np.zeros(X.shape[0])\n","        correct = 0 #cal Accuracy\n","        for it in range(X.shape[0]):\n","          i = np.random.randint(X.shape[0])\n","          #forward\n","          y_hat = self.forward(X[i])\n","\n","          #compute loss\n","          loss[it], delta = self.cross_entropy_loss(y_hat, y[i])\n","          #backward\n","          self.backward(delta)\n","\n","          #updata\n","          self.update(learning_rate)\n","\n","        #cal Accuracy\n","        predict = np.argmax(predict(X), axis = 1)\n","        for i in range(predict.shape[0]):\n","          if y[i, predict[i]] == 1:\n","            correct += 1\n","\n","        to_return[k] = np.mean(loss)\n","        print(\"iteration:{0},loss:{1},Accuracy:{2}\".format(k, np.mean(loss), correct/X.shape[0]))\n","\n","    #MiniBatch SGD\n","    else:\n","      print(\"MiniBatch\")\n","      for k in range(epochs):\n","        loss = np.zeros(int(X.shape[0]/self.miniBatch)+1)\n","        shuffled_indices = np.random.permutation(X.shape[0])\n","        X_shuffled = X[shuffled_indices]\n","        y_shuffled = y[shuffled_indices]\n","        correct = 0 # cal Accuracy\n","        for it in range(0, X.shape[0], self.miniBatch):\n","          end_idx = min(it + self.miniBatch, X.shape[0])  #avoid index out of range\n","          Xi = X_shuffled[it:end_idx]\n","          yi = y_shuffled[it:end_idx]\n","          #forward\n","          y_hat = self.forward(Xi)\n","          #comput loss\n","          loss[int(it/self.miniBatch)], delta = self.cross_entropy_loss(y_hat, yi)\n","          #backward\n","          self.backward(delta)\n","          #update\n","          self.update(learning_rate)\n","\n","        #cal Accuracy\n","        predict = np.argmax(self.predict(X), axis = 1)\n","        for i in range(predict.shape[0]):\n","          if y[i, predict[i]] == 1:\n","            correct += 1\n","\n","        to_return[k] = np.mean(loss)\n","        print(\"iteration:{0},loss:{1},Accuracy:{2}\".format(k, np.mean(loss), correct/X.shape[0]))\n","\n","    return to_return\n","\n","  def predict(self, x):\n","    output = self.forward(x)\n","    return output\n"],"metadata":{"id":"GYDKd2ReEFd8","executionInfo":{"status":"ok","timestamp":1711869702356,"user_tz":-660,"elapsed":454,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":300,"outputs":[]},{"cell_type":"code","source":["#translate train_label into input true value\n","train_real = np.zeros((train_label.shape[0], 10))\n","for i in range(train_label.shape[0]):\n","  train_real[i, train_label[i]] = 1\n","train_real.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTgNl0lR2mNJ","executionInfo":{"status":"ok","timestamp":1711854276230,"user_tz":-660,"elapsed":349,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"fbf56ae0-93e3-48c4-b278-615ae7f51c96"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 10)"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["train_real[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PpAJe7ugc4b5","executionInfo":{"status":"ok","timestamp":1711854041269,"user_tz":-660,"elapsed":457,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"d1ebee66-db29-4ad8-cce3-91aeee202399"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["# @title\n","#Learning\n","nn = MLP([128, 256, 128, 10], [None, \"relu\", \"relu\", \"relu\"], momentum = 0.9, miniBatch = 4)\n","loss = nn.fit(train, train_real, learning_rate = 0.0001, epochs = 500)\n","loss[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dMEmLQFTPriI","executionInfo":{"status":"error","timestamp":1711871950973,"user_tz":-660,"elapsed":605009,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"bf8aeb0e-3afa-40e5-e3bd-172c5d670596"},"execution_count":301,"outputs":[{"output_type":"stream","name":"stdout","text":["MiniBatch\n","iteration:0,loss:1.8745303936777127,Accuracy:0.40498\n","iteration:1,loss:1.6600626415532687,Accuracy:0.4458\n","iteration:2,loss:1.5767000668219313,Accuracy:0.4671\n","iteration:3,loss:1.513613166171805,Accuracy:0.489\n","iteration:4,loss:1.463480539911761,Accuracy:0.50132\n","iteration:5,loss:1.4223891288654813,Accuracy:0.5218\n","iteration:6,loss:1.3860522802866833,Accuracy:0.53026\n","iteration:7,loss:1.3552269338975846,Accuracy:0.54166\n","iteration:8,loss:1.3283949598814744,Accuracy:0.54858\n","iteration:9,loss:1.3025012144698986,Accuracy:0.5568\n","iteration:10,loss:1.2784905917397305,Accuracy:0.57018\n","iteration:11,loss:1.2570463703835808,Accuracy:0.5755\n","iteration:12,loss:1.234410514620134,Accuracy:0.58512\n","iteration:13,loss:1.2159659432472247,Accuracy:0.58728\n","iteration:14,loss:1.1951440707316203,Accuracy:0.59898\n","iteration:15,loss:1.1781702969939192,Accuracy:0.60728\n","iteration:16,loss:1.1594125657154806,Accuracy:0.61194\n","iteration:17,loss:1.142980305613171,Accuracy:0.61614\n","iteration:18,loss:1.125622372319988,Accuracy:0.62468\n","iteration:19,loss:1.1102077151904362,Accuracy:0.6301\n","iteration:20,loss:1.093674959362215,Accuracy:0.63888\n","iteration:21,loss:1.079640758795627,Accuracy:0.63926\n","iteration:22,loss:1.062936328428035,Accuracy:0.64306\n","iteration:23,loss:1.0507677766169528,Accuracy:0.64846\n","iteration:24,loss:1.0359010163106335,Accuracy:0.65862\n","iteration:25,loss:1.02130543767685,Accuracy:0.659\n","iteration:26,loss:1.0076277456287237,Accuracy:0.66934\n","iteration:27,loss:0.9946813560369452,Accuracy:0.66666\n","iteration:28,loss:0.9816605667306286,Accuracy:0.67332\n","iteration:29,loss:0.9682759184418716,Accuracy:0.67572\n","iteration:30,loss:0.9562553470226741,Accuracy:0.68676\n","iteration:31,loss:0.943913270346836,Accuracy:0.68594\n","iteration:32,loss:0.9323705251258101,Accuracy:0.68864\n","iteration:33,loss:0.9203835346253544,Accuracy:0.69866\n","iteration:34,loss:0.9080261623815518,Accuracy:0.70448\n","iteration:35,loss:0.8991869472564694,Accuracy:0.70202\n","iteration:36,loss:0.8861061614801875,Accuracy:0.7102\n","iteration:37,loss:0.8745793942488138,Accuracy:0.71508\n","iteration:38,loss:0.8626538218275658,Accuracy:0.71618\n","iteration:39,loss:0.8534926455650964,Accuracy:0.71426\n","iteration:40,loss:0.8418698819569802,Accuracy:0.72438\n","iteration:41,loss:0.8318192423222848,Accuracy:0.72942\n","iteration:42,loss:0.820912735483012,Accuracy:0.73064\n","iteration:43,loss:0.8089002145859313,Accuracy:0.73014\n","iteration:44,loss:0.798244138594547,Accuracy:0.7328\n","iteration:45,loss:0.7903946964903459,Accuracy:0.74964\n","iteration:46,loss:0.7780026106776999,Accuracy:0.74884\n","iteration:47,loss:0.7687116209775173,Accuracy:0.75456\n","iteration:48,loss:0.7591377892749296,Accuracy:0.76224\n","iteration:49,loss:0.7497997769322479,Accuracy:0.74428\n","iteration:50,loss:0.7379797012556771,Accuracy:0.75168\n","iteration:51,loss:0.7310471421546082,Accuracy:0.76064\n","iteration:52,loss:0.7225748747350131,Accuracy:0.77636\n","iteration:53,loss:0.7131473442789991,Accuracy:0.77282\n","iteration:54,loss:0.7024145771219482,Accuracy:0.77462\n","iteration:55,loss:0.6930446412853029,Accuracy:0.7736\n","iteration:56,loss:0.6833279848094886,Accuracy:0.77328\n","iteration:57,loss:0.6729303844821138,Accuracy:0.7808\n","iteration:58,loss:0.6665401102443592,Accuracy:0.78732\n","iteration:59,loss:0.6565322555830063,Accuracy:0.78352\n","iteration:60,loss:0.6477831234971229,Accuracy:0.79922\n","iteration:61,loss:0.6400676212083621,Accuracy:0.79956\n","iteration:62,loss:0.631284500519107,Accuracy:0.8041\n","iteration:63,loss:0.6224213470003586,Accuracy:0.80534\n","iteration:64,loss:0.6165050403161145,Accuracy:0.80752\n","iteration:65,loss:0.6070023037190238,Accuracy:0.80416\n","iteration:66,loss:0.5973744579943612,Accuracy:0.80752\n","iteration:67,loss:0.5894978147472295,Accuracy:0.81596\n","iteration:68,loss:0.582977990439399,Accuracy:0.81778\n","iteration:69,loss:0.5720346825752294,Accuracy:0.82606\n","iteration:70,loss:0.5657846134519019,Accuracy:0.82304\n","iteration:71,loss:0.5567378237539615,Accuracy:0.82438\n","iteration:72,loss:0.5514598518602088,Accuracy:0.82258\n","iteration:73,loss:0.5421284057150508,Accuracy:0.83072\n","iteration:74,loss:0.5343045319308041,Accuracy:0.81614\n","iteration:75,loss:0.528102287204634,Accuracy:0.8275\n","iteration:76,loss:0.5193743916224619,Accuracy:0.83608\n","iteration:77,loss:0.5132962532658676,Accuracy:0.84408\n","iteration:78,loss:0.5069916739273291,Accuracy:0.8534\n","iteration:79,loss:0.4991810809887462,Accuracy:0.85182\n","iteration:80,loss:0.4912859254727998,Accuracy:0.84948\n","iteration:81,loss:0.48567968958119967,Accuracy:0.85004\n","iteration:82,loss:0.4778675319400733,Accuracy:0.85186\n","iteration:83,loss:0.46988524037704954,Accuracy:0.8502\n","iteration:84,loss:0.46446067658960827,Accuracy:0.85604\n","iteration:85,loss:0.4593774538507392,Accuracy:0.85772\n","iteration:86,loss:0.4527807608959662,Accuracy:0.86232\n","iteration:87,loss:0.4454730248005957,Accuracy:0.8648\n","iteration:88,loss:0.4399810811065623,Accuracy:0.88094\n","iteration:89,loss:0.43487820604641475,Accuracy:0.86778\n","iteration:90,loss:0.428915895253668,Accuracy:0.87782\n","iteration:91,loss:0.42040999802855616,Accuracy:0.87398\n","iteration:92,loss:0.41698478795731536,Accuracy:0.87772\n","iteration:93,loss:0.40939626715801974,Accuracy:0.87446\n","iteration:94,loss:0.40459849563856565,Accuracy:0.87776\n","iteration:95,loss:0.39756946928408776,Accuracy:0.88168\n","iteration:96,loss:0.39162252517232343,Accuracy:0.88154\n","iteration:97,loss:0.38932155096324106,Accuracy:0.88938\n","iteration:98,loss:0.38254928796237014,Accuracy:0.88986\n","iteration:99,loss:0.37509197031257796,Accuracy:0.88326\n","iteration:100,loss:0.37157483377582673,Accuracy:0.89404\n","iteration:101,loss:0.3645596320033907,Accuracy:0.89748\n","iteration:102,loss:0.3615588914942215,Accuracy:0.90002\n","iteration:103,loss:0.3510088743806026,Accuracy:0.89524\n","iteration:104,loss:0.3525502975664036,Accuracy:0.90032\n","iteration:105,loss:0.3449133203222165,Accuracy:0.89536\n","iteration:106,loss:0.3380226127159996,Accuracy:0.89542\n","iteration:107,loss:0.33513251029488683,Accuracy:0.90788\n","iteration:108,loss:0.32948099027372574,Accuracy:0.91078\n","iteration:109,loss:0.32699030401465545,Accuracy:0.90486\n","iteration:110,loss:0.31971630759790276,Accuracy:0.90184\n","iteration:111,loss:0.31419121378629294,Accuracy:0.9152\n","iteration:112,loss:0.30992127619085125,Accuracy:0.91444\n","iteration:113,loss:0.3067249795366639,Accuracy:0.92072\n","iteration:114,loss:0.2999225299261178,Accuracy:0.91238\n","iteration:115,loss:0.29536427835467893,Accuracy:0.9115\n","iteration:116,loss:0.2928765263809119,Accuracy:0.91598\n","iteration:117,loss:0.28880879324559866,Accuracy:0.91606\n","iteration:118,loss:0.28529021455602677,Accuracy:0.92332\n","iteration:119,loss:0.27985565085254094,Accuracy:0.92378\n","iteration:120,loss:0.2750889849574134,Accuracy:0.92292\n","iteration:121,loss:0.2719848543275962,Accuracy:0.92256\n","iteration:122,loss:0.266601391043363,Accuracy:0.93102\n","iteration:123,loss:0.26571917918874627,Accuracy:0.929\n","iteration:124,loss:0.2593875435087211,Accuracy:0.92192\n","iteration:125,loss:0.2530917861946394,Accuracy:0.93168\n","iteration:126,loss:0.25144810334229933,Accuracy:0.92344\n","iteration:127,loss:0.24484086404092073,Accuracy:0.93784\n","iteration:128,loss:0.24372949904072155,Accuracy:0.92962\n","iteration:129,loss:0.23979529130142946,Accuracy:0.9314\n","iteration:130,loss:0.2366777850404433,Accuracy:0.94358\n","iteration:131,loss:0.23004954053034907,Accuracy:0.93464\n","iteration:132,loss:0.23210173166689646,Accuracy:0.92556\n","iteration:133,loss:0.22404141539793707,Accuracy:0.94588\n","iteration:134,loss:0.22029154231790557,Accuracy:0.93888\n","iteration:135,loss:0.21713883788990798,Accuracy:0.93806\n","iteration:136,loss:0.21430739136372107,Accuracy:0.94324\n","iteration:137,loss:0.20935417790662766,Accuracy:0.94984\n","iteration:138,loss:0.20749812035241363,Accuracy:0.92678\n","iteration:139,loss:0.20115612918084178,Accuracy:0.9375\n","iteration:140,loss:0.19667910874986572,Accuracy:0.94534\n","iteration:141,loss:0.193939166370222,Accuracy:0.94524\n","iteration:142,loss:0.19453804214801476,Accuracy:0.95286\n","iteration:143,loss:0.18925188384578462,Accuracy:0.95246\n","iteration:144,loss:0.18441816425434404,Accuracy:0.9556\n","iteration:145,loss:0.18685084809586494,Accuracy:0.9455\n","iteration:146,loss:0.1767414436412351,Accuracy:0.95106\n","iteration:147,loss:0.17678710318255136,Accuracy:0.95114\n","iteration:148,loss:0.1731628630748715,Accuracy:0.95162\n","iteration:149,loss:0.1697392002578132,Accuracy:0.95544\n","iteration:150,loss:0.17023186578565494,Accuracy:0.95428\n","iteration:151,loss:0.16400953854264932,Accuracy:0.96414\n","iteration:152,loss:0.16140097592419003,Accuracy:0.95214\n","iteration:153,loss:0.1601000560982073,Accuracy:0.96324\n","iteration:154,loss:0.14861484617929507,Accuracy:0.96022\n","iteration:155,loss:0.15058060380125654,Accuracy:0.96188\n","iteration:156,loss:0.14498475090786941,Accuracy:0.96474\n","iteration:157,loss:0.1482133219939914,Accuracy:0.96874\n","iteration:158,loss:0.14140145635384424,Accuracy:0.96694\n","iteration:159,loss:0.1417790300717301,Accuracy:0.9628\n","iteration:160,loss:0.14195934342299305,Accuracy:0.9596\n","iteration:161,loss:0.13593065703909435,Accuracy:0.9629\n","iteration:162,loss:0.13355110523955416,Accuracy:0.97674\n","iteration:163,loss:0.12816003394153141,Accuracy:0.97146\n","iteration:164,loss:0.12634956427175378,Accuracy:0.96858\n","iteration:165,loss:0.12320407090976315,Accuracy:0.96792\n","iteration:166,loss:0.11990679959394603,Accuracy:0.97574\n","iteration:167,loss:0.11768038402244552,Accuracy:0.97834\n","iteration:168,loss:0.11556307249761279,Accuracy:0.97288\n","iteration:169,loss:0.11735212087895747,Accuracy:0.97212\n","iteration:170,loss:0.11288799365685122,Accuracy:0.97598\n","iteration:171,loss:0.10636312726392019,Accuracy:0.9722\n","iteration:172,loss:0.1084376571439507,Accuracy:0.97844\n","iteration:173,loss:0.10491646465649901,Accuracy:0.97566\n","iteration:174,loss:0.10553822014627728,Accuracy:0.96604\n","iteration:175,loss:0.10447571476551454,Accuracy:0.97388\n","iteration:176,loss:0.0988820862219238,Accuracy:0.98198\n","iteration:177,loss:0.0956344561953049,Accuracy:0.98138\n","iteration:178,loss:0.08949645721653723,Accuracy:0.9823\n","iteration:179,loss:0.0920022774085683,Accuracy:0.97586\n","iteration:180,loss:0.08717842368305134,Accuracy:0.98586\n","iteration:181,loss:0.08228195831679314,Accuracy:0.98514\n","iteration:182,loss:0.08039912835426276,Accuracy:0.98674\n","iteration:183,loss:0.0771198724792402,Accuracy:0.9824\n","iteration:184,loss:0.07762544894577403,Accuracy:0.98714\n","iteration:185,loss:0.07630256026082831,Accuracy:0.99058\n","iteration:186,loss:0.06875690181111264,Accuracy:0.99008\n","iteration:187,loss:0.06816905082909415,Accuracy:0.99024\n","iteration:188,loss:0.06707304573854023,Accuracy:0.99028\n","iteration:189,loss:0.06575000923069686,Accuracy:0.98866\n","iteration:190,loss:0.06307461266731629,Accuracy:0.99386\n","iteration:191,loss:0.06072270504551038,Accuracy:0.9927\n","iteration:192,loss:0.0599588119457891,Accuracy:0.99436\n","iteration:193,loss:0.054251504442624936,Accuracy:0.99352\n","iteration:194,loss:0.0544851908944397,Accuracy:0.99468\n","iteration:195,loss:0.04989544862040536,Accuracy:0.9973\n","iteration:196,loss:0.05491295347583939,Accuracy:0.99254\n","iteration:197,loss:0.04794893147895325,Accuracy:0.99552\n","iteration:198,loss:0.04407695547263301,Accuracy:0.9971\n","iteration:199,loss:0.04470326526773014,Accuracy:0.99494\n","iteration:200,loss:0.04210874532360432,Accuracy:0.99414\n","iteration:201,loss:0.04381722426011714,Accuracy:0.99768\n","iteration:202,loss:0.04004840713882576,Accuracy:0.99734\n","iteration:203,loss:0.03714469793333585,Accuracy:0.99724\n","iteration:204,loss:0.035709541022716576,Accuracy:0.99722\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-301-1a724abc872d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-300-6c3fe30fb94a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, learning_rate, epochs)\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminiBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m           \u001b[0;31m#backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m           \u001b[0;31m#update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-300-6c3fe30fb94a>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#delta = self.layers[-1].backward(delta, output_layer = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;31m#update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-263-2f7697db4d17>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, delta, output_layer)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_deriv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiHaJPskOzJv","executionInfo":{"status":"ok","timestamp":1711871954394,"user_tz":-660,"elapsed":2,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"4c59e80c-6928-475f-f844-8457bfef669a"},"execution_count":302,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ -6.40101763,   2.72903876,   1.50171052, ...,   0.22933369,\n","         -0.1535829 ,   0.54404128],\n","       [  0.82978338,  -0.94994322,   6.0037526 , ...,   0.04319449,\n","         -0.0157158 ,  -0.28907615],\n","       [  7.73019978, -11.52210233,  -2.75362051, ...,   0.01458726,\n","         -0.35582987,   0.18428758],\n","       ...,\n","       [  0.70734659, -11.34252124,  -0.39391488, ...,  -0.49020993,\n","         -0.21487252,  -0.03641533],\n","       [ 11.36790901,  -3.37597765,   5.56619766, ...,  -0.63245635,\n","         -0.07775427,   0.56149881],\n","       [  4.19279645,  -1.18418848,  -4.44596297, ...,  -0.04935812,\n","          0.16881497,   0.07433337]])"]},"metadata":{},"execution_count":302}]},{"cell_type":"code","source":["train_output = nn.predict(train)"],"metadata":{"id":"cfUAOWMh2lbp","executionInfo":{"status":"ok","timestamp":1711871956073,"user_tz":-660,"elapsed":1132,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":303,"outputs":[]},{"cell_type":"code","source":["predict = np.argmax(train_output, axis = 1)"],"metadata":{"id":"xYkFWMCdUeL6","executionInfo":{"status":"ok","timestamp":1711871956074,"user_tz":-660,"elapsed":2,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":304,"outputs":[]},{"cell_type":"code","source":["correct = 0\n","for i in range(train_label.shape[0]):\n","  if train_label[i] == predict[i]:\n","    correct += 1\n","correct / train_label.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hr40IthNYytB","executionInfo":{"status":"ok","timestamp":1711871957864,"user_tz":-660,"elapsed":3,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"e8b8e3f2-3dbc-42d4-922c-ea610396d2c6"},"execution_count":305,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.99822"]},"metadata":{},"execution_count":305}]},{"cell_type":"code","source":["test_output = nn.predict(test)"],"metadata":{"id":"A0nggxZznQFI","executionInfo":{"status":"ok","timestamp":1711871959696,"user_tz":-660,"elapsed":716,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":306,"outputs":[]},{"cell_type":"code","source":["predict = np.argmax(test_output, axis = 1)"],"metadata":{"id":"cDwNO18xnhLJ","executionInfo":{"status":"ok","timestamp":1711871959697,"user_tz":-660,"elapsed":2,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}}},"execution_count":307,"outputs":[]},{"cell_type":"code","source":["correct = 0\n","for i in range(test_label.shape[0]):\n","  if test_label[i] == predict[i]:\n","    correct += 1\n","correct / test_label.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuE21q7CnkdE","executionInfo":{"status":"ok","timestamp":1711871960468,"user_tz":-660,"elapsed":387,"user":{"displayName":"Tianlan Tang","userId":"12627885625982252383"}},"outputId":"14791e9f-9ecd-4a0a-c80e-1b0f6deb7d81"},"execution_count":308,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5033"]},"metadata":{},"execution_count":308}]}]}